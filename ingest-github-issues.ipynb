{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4465631-d183-4a6b-80af-7add2fc281e6",
   "metadata": {},
   "source": [
    "# Add Github Issues to Qdrant Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d17d7b-54d0-42ec-a7f1-36144c1b2d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U qdrant-client sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8fabc11-5d29-412d-a13b-223a5865da4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alokdwivedi/dev/github/dashamlav/llm/langchain/lang_chain/lib/python3.9/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import models, QdrantClient\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd2c829f-8d20-4fa7-9a27-19c5d8b5c98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00cb908c-862a-42bb-8e0c-17d734524247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "localhost:6333\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "QDRANT_COLLECTION_NAME=\"github_issues_coll\"\n",
    "OPEN_AI_MODEL_NAME=\"gpt-4o-mini\" #Â \"gpt-3.5-turbo-16k\"\n",
    "CONFIG_FILE_PATH = '.7ytrepmnt'\n",
    "dotenv.load_dotenv(CONFIG_FILE_PATH)\n",
    "print(os.getenv(\"QDRANT_HOST_URL\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97a51a2d-e4d0-4f6b-b462-4c6ba43771cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/78399709/limit-context-token-on-document-retrieval-chains\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "def get_qdrant_client():\n",
    "        qdrant_url = os.getenv(\"QDRANT_HOST_URL\")\n",
    "        qdrant_api_key = os.getenv(\"QDRANT_API_KEY\")\n",
    "        \n",
    "        return QdrantClient(\n",
    "            url=qdrant_url, \n",
    "            api_key=qdrant_api_key,\n",
    "        )\n",
    "\n",
    "def get_existing_vector_store(collection_identity):\n",
    "        qdrant_client = get_qdrant_client()\n",
    "\n",
    "        embeddings=OpenAIEmbeddings()\n",
    "        return Qdrant(\n",
    "            client=qdrant_client,\n",
    "            collection_name=collection_identity,\n",
    "            embeddings=embeddings,\n",
    "        )\n",
    "\n",
    "def get_chunked_text(file_name):\n",
    "    with open(file_name, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "        text_splitter = CharacterTextSplitter(\n",
    "            separator='\\n',\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=150,\n",
    "            length_function=len\n",
    "        )\n",
    "        return text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db84c6c1-7ea7-434d-b4c0-b8e60599c254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.brainbyte.io/vector-search-using-openai-embeddings-with-qdrant/\n",
    "get_qdrant_client().create_collection(\n",
    "    collection_name=QDRANT_COLLECTION_NAME,\n",
    "    vectors_config=VectorParams(size=1536, distance=Distance.COSINE),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f654c9e4-5bf1-4dad-86a9-ce294417dbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_text_temp = get_chunked_text(f\"gh_issues/github_issues_1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "067bb58e-29d2-465e-9d18-05153d746326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunked_text_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ce0143-87bd-4794-a81c-370cd0fea38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qdrant_collection = get_existing_vector_store(QDRANT_COLLECTION_NAME)\n",
    "for page_num in range(19):\n",
    "    chunked_text = get_chunked_text(f\"gh_issues/github_issues_{page_num}.txt\")\n",
    "    vector_ids = qdrant_collection.add_texts(chunked_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "864eb66c-0b43-4510-8495-66a1aba9f941",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Facing issues with common ForkJoinPool used in ExecutableJar\"\n",
    "found_docs = qdrant_collection.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c96d1e44-c20f-4d0c-84b3-5ea9099ac7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total docs found:4\n",
      "***End of Issue number:39928***\n",
      "***Begining of Issue number:39843***\n",
      "Issue Title:Incorrect classloader used by common ForkJoinPool when using Executable Jar\n",
      "Issue Body:# Context\n",
      "I created this issue as a bug report or enhancement proposal - depending on how would you classify current behaviour.\n",
      "I have a spring application that I am building using \"org.springframework.boot gradle\" plugin. This plugin builds Executable Jar and War as described in documentation:\n",
      "https://docs.spring.io/spring-boot/docs/current/reference/html/executable-jar.html\n",
      "# Problem\n",
      "Executable Jar uses custom class loader: `org.springframework.boot.loader.launch.LaunchedClassLoader` when running the application. \n",
      "This class loader is not propagated to the common ForkJoinPool, which uses system class loader by default.\n",
      "Take a code like that:\n",
      "```\n",
      "IntStream.rangeClosed(0, 4)\n",
      "    .parallel()\n",
      "    .forEach(i -> System.out.println(Thread.currentThread().getName() + \" \" + Thread.currentThread().getContextClassLoader()));\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total docs found:{len(found_docs)}\")\n",
    "print(found_docs[0].page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5adcac-58bc-47da-a219-aec5bc4a0dc4",
   "metadata": {},
   "source": [
    "## Ingest some Closed issues as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db56d58-84cb-4468-86e6-c3b2f8d4209d",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_collection = get_existing_vector_store(QDRANT_COLLECTION_NAME)\n",
    "for page_num in range(20):\n",
    "    chunked_text = get_chunked_text(f\"gh_issues/closed/github_issues_{page_num}.txt\")\n",
    "    vector_ids = qdrant_collection.add_texts(chunked_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "822c7e84-67fe-4d1e-8daa-e39a92cc81b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total docs found:4\n",
      "Comments:\n",
      "***End of Issue number:43202***\n",
      "***Begining of Issue number:43200***\n",
      "Issue Title:Spring Boot 3.3.x dependencies do not converge for Micrometer Tracing and OpenTelemetry\n",
      "Issue Body:Found that `org.springframework.boot:spring-boot-dependencies:3.3.5` specifies `opentelemetry-bom` version `1.37.0` and `micrometer-tracing-bom` version `1.3.5`, but that version of micrometer-tracing depends on opentelemetry `1.38.0` dependencies.\n",
      "This can be worked around by overloading the version of `opentelemetry-bom` to be version `1.38.0` in the Maven `<dependencyManagement>` section.\n"
     ]
    }
   ],
   "source": [
    "query = \"Facing issues with Micrometer Tracing and OpenTelemetry\"\n",
    "found_docs = qdrant_collection.similarity_search(query)\n",
    "print(f\"Total docs found:{len(found_docs)}\")\n",
    "print(found_docs[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f87902-8faa-421c-a58c-980d47716d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
