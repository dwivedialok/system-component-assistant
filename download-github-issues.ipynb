{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5e3119-c140-4bda-9e55-013426660034",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyGithub docarray qdrant-client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "796b466b-ad4e-486a-bb86-b49376d78d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "localhost:6333\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import json\n",
    "import time\n",
    "\n",
    "OPEN_AI_MODEL_NAME=\"gpt-4o-mini\"\n",
    "CONFIG_FILE_PATH = '.7ytrepmnt'\n",
    "dotenv.load_dotenv(CONFIG_FILE_PATH)\n",
    "print(os.getenv(\"QDRANT_HOST_URL\"))\n",
    "GITTHUB_TOKEN  = os.getenv(\"GITHUB_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277c26e3-4f9a-4317-85dd-f199bff4e4e2",
   "metadata": {},
   "source": [
    "## Load Github Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "537c1821-aa67-4a83-88d8-be6a1d1f5e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The creator of the repository is: spring-projects\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "repo = \"spring-projects/spring-boot\"\n",
    "url = f\"https://api.github.com/repos/{repo}\"\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "creator = data['owner']['login']\n",
    "print(f\"The creator of the repository is: {creator}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "33b07453-1f16-41cd-8091-13a75637c03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import GitHubIssuesLoader\n",
    "repo_url = f\"https://github.com/{repo}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "00f76712-5c04-4e12-af81-da75f6ff9f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ghLoader = GitHubIssuesLoader(\n",
    "    repo=repo,\n",
    "    access_token=GITTHUB_TOKEN,  # delete/comment out this argument if you've set the access token as an env var.\n",
    "    creator=creator,\n",
    "    include_prs=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92691ec7-f292-4dc8-aacb-4f1077b04e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "ghDocs = ghLoader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33532df-3933-4e27-99fb-f7f3b28bd610",
   "metadata": {},
   "source": [
    "## Helper function to get issues page by page and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e54b6b9-c220-4b9c-bd7d-be3b29b865f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_github_issues_as_dict(repo_url, issue_state, token):\n",
    "    '''\n",
    "    since GitHub doesn't make it super easy to download GitHub issues...\n",
    "    :param repo_url: the full URL of the repo (don't include the trailing \"/\").\n",
    "    :param token: a GitHub Personal Access Token (create from GitHub itself)\n",
    "    :return: a dictionary that can be easily json-ified with the relevant info from the issues.\n",
    "    '''\n",
    "    assert isinstance(repo_url, str) and not repo_url.endswith(\"/\") and \"/\" in repo_url, \"need nice repo_url\"\n",
    "    assert isinstance(token, str), \"need nice token\"\n",
    "    import github  # pip install PyGithub\n",
    "    g = github.Github(token)\n",
    "    user_str, repo_str = repo_url.replace(\"https://github.com/\", \"\").split(\"/\")\n",
    "    user = g.get_user(user_str)\n",
    "    repo = user.get_repo(repo_str)\n",
    "    issues = repo.get_issues(state=issue_state)\n",
    "    return issues\n",
    "\n",
    "def get_issues_pageCount(issues, coun_per_page=30):\n",
    "    return round(issues.totalCount / coun_per_page) + 1\n",
    "    \n",
    "def get_issues_by_page(issues,page_num):\n",
    "     # the number 30 appears to hardcoded into the PyGitHub - maybe there is a better way to do this part?\n",
    "     # real_issues = [_ for i in range(round(issues.totalCount / 30) + 1) for _ in issues.get_page(i) if\n",
    "     #              not _.pull_request]\n",
    "    \n",
    "    rtn = {}\n",
    "    for iss in issues.get_page(page_num):\n",
    "        if not iss.pull_request:\n",
    "            iss_dict = {\"title\": iss.title,\n",
    "                        \"body\": iss.body,\n",
    "                        \"state\": iss.state,\n",
    "                        \"comments\": [_.body for _ in iss.get_comments()]}\n",
    "            rtn[iss.number] = iss_dict\n",
    "    return rtn\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96c7ce80-b0d7-4a4e-9801-72fa5c5554d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_issues_to_file(file, page_number):\n",
    "    \"\"\"\n",
    "    Writes GitHub issues from a specified page to an already opened file.\n",
    "\n",
    "    Args:\n",
    "        file: An open file handle.\n",
    "        page_number: The page number of issues to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    issue_page = issues.get_page(page_number)\n",
    "    for iss in issue_page:\n",
    "        if not iss.pull_request:\n",
    "            file.write(f\"***Begining of Issue number:{iss.number}***\\n\")\n",
    "            file.write(f\"Issue Title:{iss.title}\\n\")\n",
    "            file.write(f\"Issue Body:{iss.body}\\n\")\n",
    "            file.write(\"Comments:\\n\")\n",
    "            for comment in iss.get_comments():\n",
    "                file.write(f\"{comment.body}\\n\")\n",
    "            file.write(f\"***End of Issue number:{iss.number}***\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d3fb85-e90c-4556-9df9-fc52a42c06b9",
   "metadata": {},
   "source": [
    "## Fetch issues for configured repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "88e21cbd-7ec2-4e55-bcf9-69e3818b2803",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_url = f\"https://github.com/{repo}\"\n",
    "token = os.getenv(\"GITHUB_TOKEN\")\n",
    "issue_state = \"open\" # other values - \"closed\", \"all\"\n",
    "issues = download_github_issues_as_dict(repo_url,issue_state,token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "474f3bfc-0e0c-4c5f-a20f-6c8dc9eef19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Issues count is: 541\n",
      "Total pages for navigating all issues: 19\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Issues count is: {issues.totalCount}\")\n",
    "issues_page_count = get_issues_pageCount(issues)\n",
    "print(f\"Total pages for navigating all issues: {issues_page_count}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b4482301-6214-4ba5-9ce5-c6745d17c254",
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_dict = get_issues_by_page(issues,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24798117-52b9-4cdf-897e-424df4670069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Begining of Issue number:43079***\n",
      "Issue Title:Investigate ClientHttpConnector builders for WebClient with a similar design to ClientHttpRequestFactoryBuilder\n",
      "Issue Body:<!--\n",
      "Thanks for raising a Spring Boot issue. Please take the time to review the following\n",
      "categories as some of them do not apply here.\n",
      "\n",
      "🙅 \"Please DO NOT Raise an Issue\" Cases\n",
      "- Question\n",
      "STOP!! Please ask questions about how to use something, or to understand why something isn't\n",
      "working as you expect it to, on Stack Overflow using the spring-boot tag.\n",
      "- Security Vulnerability\n",
      "STOP!! Please don't raise security vulnerabilities here. Head over to https://spring.io/security-policy to learn how to disclose them responsibly.\n",
      "- Managed Dependency Upgrade\n",
      "You DO NOT need to raise an issue for a managed dependency version upgrade as there's a semi-automatic process for checking managed dependencies for new versions before a release. BUT pull requests for upgrades that are more involved than just a version property change are still most welcome.\n",
      "- With an Immediate Pull Request\n",
      "An issue will be closed as a duplicate of the immediate pull request, so you don't have to raise an issue if you plan to create a pull request immediately.\n",
      "\n",
      "🐞 Bug report (please don't include this emoji/text, just add your details)\n",
      "Please provide details of the problem, including the version of Spring Boot that you\n",
      "are using. If possible, please provide a test case or sample application that reproduces\n",
      "the problem. This makes it much easier for us to diagnose the problem and to verify that\n",
      "we have fixed it.\n",
      "\n",
      "🎁 Enhancement (please don't include this emoji/text, just add your details)\n",
      "Please start by describing the problem that you are trying to solve. There may already\n",
      "be a solution, or there may be a way to solve it that you hadn't considered.\n",
      "\n",
      "\n",
      "TIP: You can always edit your issue if it isn't formatted correctly.\n",
      "     See https://guides.github.com/features/mastering-markdown \n",
      "-->\n",
      "\n",
      "The new ClientHttpRequestFactoryBuilder is fantastic. Are there any plans or desire to bring a similar builder for ClientHttpConnectors for configuring WebClients?\n",
      "\n",
      "\n",
      "Comments:\n",
      "It would be a good idea for us to investigate options. I'll repurpose this issue to do that.\n",
      "***End of Issue number:43079***\n"
     ]
    }
   ],
   "source": [
    "issuePage1 = issues.get_page(1)\n",
    "for iss in issuePage1:\n",
    "    if not iss.pull_request:\n",
    "        print(f\"***Begining of Issue number:{iss.number}***\")\n",
    "        print(f\"Issue Title:{iss.title}\")\n",
    "        print(f\"Issue Body:{iss.body}\")\n",
    "        print(\"Comments:\")\n",
    "        for comment in iss.get_comments():\n",
    "            print(f\"{comment.body}\")\n",
    "        print(f\"***End of Issue number:{iss.number}***\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119b1b80-64c7-4f7a-baef-889c63c86c77",
   "metadata": {},
   "source": [
    "## Save all issues page by page as text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dce39986-0f8e-41f3-9113-6a88cb17dd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GitHub issues from page 0 appended to 'gh_issues/github_issues_0.txt'\n",
      "GitHub issues from page 1 appended to 'gh_issues/github_issues_1.txt'\n",
      "GitHub issues from page 2 appended to 'gh_issues/github_issues_2.txt'\n",
      "GitHub issues from page 3 appended to 'gh_issues/github_issues_3.txt'\n",
      "GitHub issues from page 4 appended to 'gh_issues/github_issues_4.txt'\n",
      "GitHub issues from page 5 appended to 'gh_issues/github_issues_5.txt'\n",
      "GitHub issues from page 6 appended to 'gh_issues/github_issues_6.txt'\n",
      "GitHub issues from page 7 appended to 'gh_issues/github_issues_7.txt'\n",
      "GitHub issues from page 8 appended to 'gh_issues/github_issues_8.txt'\n",
      "GitHub issues from page 9 appended to 'gh_issues/github_issues_9.txt'\n",
      "GitHub issues from page 10 appended to 'gh_issues/github_issues_10.txt'\n",
      "GitHub issues from page 11 appended to 'gh_issues/github_issues_11.txt'\n",
      "GitHub issues from page 12 appended to 'gh_issues/github_issues_12.txt'\n",
      "GitHub issues from page 13 appended to 'gh_issues/github_issues_13.txt'\n",
      "GitHub issues from page 14 appended to 'gh_issues/github_issues_14.txt'\n",
      "GitHub issues from page 15 appended to 'gh_issues/github_issues_15.txt'\n",
      "GitHub issues from page 16 appended to 'gh_issues/github_issues_16.txt'\n",
      "GitHub issues from page 17 appended to 'gh_issues/github_issues_17.txt'\n",
      "GitHub issues from page 18 appended to 'gh_issues/github_issues_18.txt'\n"
     ]
    }
   ],
   "source": [
    "for page_number_to_write in range(issues_page_count):  \n",
    "    file_name = f\"gh_issues/github_issues_{page_number_to_write}.txt\"\n",
    "    with open(file_name, \"w\") as issues_file:\n",
    "        write_issues_to_file(issues_file, page_number_to_write)\n",
    "    \n",
    "    print(f\"GitHub issues from page {page_number_to_write} appended to '{file_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897e08b8-d554-4272-8683-32b4b4e55439",
   "metadata": {},
   "source": [
    "## Load the text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "28b875f9-eaaf-44a0-878b-a6529d0db942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = DirectoryLoader('./', glob=\"gh_issues/*.txt\", loader_cls=TextLoader, silent_errors=True)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a1dba0a7-661e-4bec-815b-e5414d38202c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadd0472-7ab0-4a1d-8d88-b72cc1f2ad6a",
   "metadata": {},
   "source": [
    "## Querying via default Index engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc27d1a-c116-42af-94fc-04889f14958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "\n",
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch\n",
    ").from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f9d5c7-9bca-422b-8130-388121f12547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query =\"I am using custom arguments in PromptTemplate and GraphCypherQAChain and getting missing key error. what could be reason\"\n",
    "query1 =  \"Facing issues with common ForkJoinPool used in ExecutableJar\"\n",
    "response = index.query(query1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563b60b6-ed62-41d2-9892-6b03b4771701",
   "metadata": {},
   "source": [
    "## Using QA Chain Retriver and LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3d64a0-58b6-42a9-927a-1bbd2ec7dfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(\n",
    "        separator='\\n',\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len\n",
    "    )\n",
    "texts = text_splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd3657b-c66d-4e79-a737-359cb44a0656",
   "metadata": {},
   "source": [
    "## Use Existing Qdrant VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7bae28a6-7857-4b51-a87b-a6cb2bb3f1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "localhost:6333\n"
     ]
    }
   ],
   "source": [
    "# https://python.langchain.com/v0.1/docs/integrations/vectorstores/qdrant/\n",
    "qdrant_url = os.getenv(\"QDRANT_HOST_URL\")\n",
    "# qdrant_api_key = os.getenv(\"QDRANT_API_KEY\")\n",
    "print(qdrant_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dbbadda6-11ed-4a1f-baef-3dd196ab7bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "def get_existing_vector_store(collection_identity):\n",
    "        qdrant_url = os.getenv(\"QDRANT_HOST_URL\")\n",
    "        # qdrant_api_key = os.getenv(\"QDRANT_API_KEY\")\n",
    "        \n",
    "        qdrant_client = QdrantClient(\n",
    "            url=qdrant_url \n",
    "            # api_key=qdrant_api_key,\n",
    "        )\n",
    "\n",
    "        embeddings=OpenAIEmbeddings()\n",
    "        return Qdrant(\n",
    "            client=qdrant_client,\n",
    "            collection_name=collection_identity,\n",
    "            embeddings=embeddings,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5984586d-0288-49e9-a892-1ac9c95e915c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alokdwivedi/dev/github/dashamlav/llm/langchain/lang_chain/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "QDRANT_COLL_NAME = \"github_issues_coll\"\n",
    "qdrant = get_existing_vector_store(QDRANT_COLL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "866bc2a0-ebc7-440b-afe4-1221e7e7d125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total docs found:4\n",
      "***End of Issue number:39928***\n",
      "***Begining of Issue number:39843***\n",
      "Issue Title:Incorrect classloader used by common ForkJoinPool when using Executable Jar\n",
      "Issue Body:# Context\n",
      "I created this issue as a bug report or enhancement proposal - depending on how would you classify current behaviour.\n",
      "I have a spring application that I am building using \"org.springframework.boot gradle\" plugin. This plugin builds Executable Jar and War as described in documentation:\n",
      "https://docs.spring.io/spring-boot/docs/current/reference/html/executable-jar.html\n",
      "# Problem\n",
      "Executable Jar uses custom class loader: `org.springframework.boot.loader.launch.LaunchedClassLoader` when running the application. \n",
      "This class loader is not propagated to the common ForkJoinPool, which uses system class loader by default.\n",
      "Take a code like that:\n",
      "```\n",
      "IntStream.rangeClosed(0, 4)\n",
      "    .parallel()\n",
      "    .forEach(i -> System.out.println(Thread.currentThread().getName() + \" \" + Thread.currentThread().getContextClassLoader()));\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "query = \"Facing issues with common ForkJoinPool used in ExecutableJar\"\n",
    "found_docs = qdrant.similarity_search(query)\n",
    "print(f\"Total docs found:{len(found_docs)}\")\n",
    "print(found_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2861dda8-a695-4c81-8746-32247405f0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "retriever = qdrant.as_retriever(search_type=\"mmr\",search_kwargs={\"k\": 2, \"fetch_k\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "90125015-2344-4520-8ee6-c0f145a4df6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "921b7774-c614-46fc-8d38-609fd8020ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total docs found:2\n",
      "***End of Issue number:39928***\n",
      "***Begining of Issue number:39843***\n",
      "Issue Title:Incorrect classloader used by common ForkJoinPool when using Executable Jar\n",
      "Issue Body:# Context\n",
      "I created this issue as a bug report or enhancement proposal - depending on how would you classify current behaviour.\n",
      "I have a spring application that I am building using \"org.springframework.boot gradle\" plugin. This plugin builds Executable Jar and War as described in documentation:\n",
      "https://docs.spring.io/spring-boot/docs/current/reference/html/executable-jar.html\n",
      "# Problem\n",
      "Executable Jar uses custom class loader: `org.springframework.boot.loader.launch.LaunchedClassLoader` when running the application. \n",
      "This class loader is not propagated to the common ForkJoinPool, which uses system class loader by default.\n",
      "Take a code like that:\n",
      "```\n",
      "IntStream.rangeClosed(0, 4)\n",
      "    .parallel()\n",
      "    .forEach(i -> System.out.println(Thread.currentThread().getName() + \" \" + Thread.currentThread().getContextClassLoader()));\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total docs found:{len(results)}\")\n",
    "print(results[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fa5906d1-2de1-4a33-840e-25bcf3ea8f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  https://stackoverflow.com/questions/78399709/limit-context-token-on-document-retrieval-chains\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize a chat model from OpenAI with no randomness in responses (temperature=0)\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# Create a document compressor using the initialized chat model\n",
    "# compressor = LLMChainExtractor.from_llm(llm)\n",
    "\n",
    "# Create a retriever that uses contextual compression\n",
    "# compression_retriever = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=retriever)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "29783d9a-4f8c-452f-8bc6-f1b7bf143d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "qa_stuff = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever, \n",
    "    verbose=True\n",
    ")\n",
    "query2 =  \"Facing issues with common ForkJoinPool used in ExecutableJar. How to resolve this\"\n",
    "response = qa_stuff.run(query2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "59b6e877-b575-4eda-a051-cf819ca54ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To resolve the issue with the common ForkJoinPool not using the custom class loader in an Executable Jar, you can try the following approaches:\n",
      "\n",
      "1. **Custom ForkJoinPool**: Wrap your application entry points in a custom ForkJoinPool that uses the desired class loader. This way, you can ensure that the ForkJoinPool created within your application context uses the correct class loader.\n",
      "\n",
      "2. **Alternative Jar Solutions**: Consider building your Spring application jar without using the Executable Jar format. You can explore alternative methods mentioned in the Spring Boot documentation under \"Alternative Single Jar Solutions.\" This may involve building a fat jar using tools like Gradle Shadow Plugin or other solutions that allow you to control the class loading behavior.\n",
      "\n",
      "3. **Unpack Fat Jar**: If building a fat jar for your Spring application is challenging, you can try unpacking the fat jar and configuring the class loading behavior manually. This approach may require additional configuration and handling of dependencies, but it can help you ensure that the class loader is set correctly for the ForkJoinPool.\n",
      "\n",
      "These are some potential solutions to address the issue with the common ForkJoinPool not using the custom class loader in an Executable Jar. You may need to experiment with these approaches to find the best fit for your specific application and requirements.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "45cb6ff8-6c5a-444f-8b5c-03a95634f50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query3 = \"JPA DDL properties are difficult to use with auto-configuration\"\n",
    "response = qa_stuff.run(query3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d6e1eeeb-0f94-4976-89b1-93be296033dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, it seems that there are challenges with using JPA DDL properties alongside auto-configuration in Spring Boot, as mentioned in the context provided. The behavior described indicates that the `spring.jpa.generate-ddl` flag may not work as expected when Hibernate auto-configuration is active. This discrepancy could lead to unexpected schema updates when upgrading to newer versions of Spring Boot.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dc8285-f275-4a6a-a35b-562c6459b039",
   "metadata": {},
   "source": [
    "## Ingest some Closed issues as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "608772fe-5ea1-40d1-926b-5a8ebb6e27a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_url = f\"https://github.com/{repo}\"\n",
    "token = os.getenv(\"GITHUB_TOKEN\")\n",
    "issue_state = \"closed\" # other values - \"closed\", \"all\"\n",
    "issues_closed = download_github_issues_as_dict(repo_url,issue_state,token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3a2b310c-b0c4-4fd6-aa5f-7ea531abc15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Issues count is: 42246\n",
      "Total pages for navigating all clsoed issues: 1409\n",
      "Total pages for clsoed issues that will be indexed: 20\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Issues count is: {issues.totalCount}\")\n",
    "issues_closed_page_count = get_issues_pageCount(issues_closed)\n",
    "max_pages_to_index = min(20, issues_closed_page_count)\n",
    "print(f\"Total pages for navigating all clsoed issues: {issues_closed_page_count}\") \n",
    "print(f\"Total pages for clsoed issues that will be indexed: {max_pages_to_index}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8e21ed5a-8a51-4e9f-82de-81e29fc771fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GitHub issues from page 0 appended to 'gh_issues/closed/github_issues_0.txt'\n",
      "GitHub issues from page 1 appended to 'gh_issues/closed/github_issues_1.txt'\n",
      "GitHub issues from page 2 appended to 'gh_issues/closed/github_issues_2.txt'\n",
      "GitHub issues from page 3 appended to 'gh_issues/closed/github_issues_3.txt'\n",
      "GitHub issues from page 4 appended to 'gh_issues/closed/github_issues_4.txt'\n",
      "GitHub issues from page 5 appended to 'gh_issues/closed/github_issues_5.txt'\n",
      "GitHub issues from page 6 appended to 'gh_issues/closed/github_issues_6.txt'\n",
      "GitHub issues from page 7 appended to 'gh_issues/closed/github_issues_7.txt'\n",
      "GitHub issues from page 8 appended to 'gh_issues/closed/github_issues_8.txt'\n",
      "GitHub issues from page 9 appended to 'gh_issues/closed/github_issues_9.txt'\n",
      "GitHub issues from page 10 appended to 'gh_issues/closed/github_issues_10.txt'\n",
      "GitHub issues from page 11 appended to 'gh_issues/closed/github_issues_11.txt'\n",
      "GitHub issues from page 12 appended to 'gh_issues/closed/github_issues_12.txt'\n",
      "GitHub issues from page 13 appended to 'gh_issues/closed/github_issues_13.txt'\n",
      "GitHub issues from page 14 appended to 'gh_issues/closed/github_issues_14.txt'\n",
      "GitHub issues from page 15 appended to 'gh_issues/closed/github_issues_15.txt'\n",
      "GitHub issues from page 16 appended to 'gh_issues/closed/github_issues_16.txt'\n",
      "GitHub issues from page 17 appended to 'gh_issues/closed/github_issues_17.txt'\n",
      "GitHub issues from page 18 appended to 'gh_issues/closed/github_issues_18.txt'\n",
      "GitHub issues from page 19 appended to 'gh_issues/closed/github_issues_19.txt'\n"
     ]
    }
   ],
   "source": [
    "for page_number_to_write in range(max_pages_to_index):  \n",
    "    file_name = f\"gh_issues/closed/github_issues_{page_number_to_write}.txt\"\n",
    "    with open(file_name, \"w\") as issues_file:\n",
    "        write_issues_to_file(issues_file, page_number_to_write)\n",
    "    \n",
    "    print(f\"GitHub issues from page {page_number_to_write} appended to '{file_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dc8468a4-a757-4184-8b93-e2c143a3e198",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "def get_chunked_text(file_name):\n",
    "    with open(file_name, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "        text_splitter = CharacterTextSplitter(\n",
    "            separator='\\n',\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=150,\n",
    "            length_function=len\n",
    "        )\n",
    "        return text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e0668ba3-1e95-4abc-b386-ec7e6cf8f8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "QDRANT_COLLECTION_NAME=\"github_issues_coll\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0823caf8-d179-4464-b4bc-a65240f1ee4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1015, which is longer than the specified 1000\n",
      "Created a chunk of size 2709, which is longer than the specified 1000\n",
      "Created a chunk of size 2709, which is longer than the specified 1000\n",
      "Created a chunk of size 2709, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "qdrant_collection = get_existing_vector_store(QDRANT_COLLECTION_NAME)\n",
    "for page_num in range(20):\n",
    "    chunked_text = get_chunked_text(f\"gh_issues/closed/github_issues_{page_num}.txt\")\n",
    "    vector_ids = qdrant_collection.add_texts(chunked_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c884e2d-0b66-429b-acb6-4fbf72ada028",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
